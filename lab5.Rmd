---
title: "Lab 5 - Data Variation and Co-Variation"
name: 
date: 
output:
  html_notebook:
    toc: yes
    toc_depth: 3
    toc_float: yes
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
editor_options:
  chunk_output_type: inline
---

## Instructions and Overview

In this assignment, we will practice graphically representing variation and covariation in a dataset. To begin you will need to import and clean your dataset. You may reference last week's lab to help with this. After this, you should follow the prompts and complete the short answer questions. At various points in this assignment, you will be asked to draw insights about your dataset after calling certain functions. When I ask you to draw an insight,I am not asking you to describe what the function does or to state the results that you get. Instead, I am asking you to interpret those results and consider what this might tell us about the issues represented in the dataset or if it might signal issues of data quality. For instance, stating "the maximum value in the age column is 999," is not an insight. Instead you should say, "the maximum value in the age column is 999, which is much higher than I would expect and may signal that the data was input wrong or that the data collectors at using 999 to represent null values."

## Getting Started

### Load the relevant libraries

```{r}
library(tidyverse)
library(lubridate)
```

### Import and clean example datasets. Other than the COVID-19 Cases dataset, which we have been using in previous labs, today we are going to explore the following:

**Hospitals in the US:** This data is published by the Department of Homeland Security on a platform called the [Homeland Infrastructure Foundation-Level Data](https://hifld-geoplatform.opendata.arcgis.com/). The data is compiled by a DHS team from the Oak Ridge National Laboratory (ORNL), the National Geospatial-Intelligence Agency (NGA), and the Homeland Security Infrastructure Program (HSIP) Team. The data is aggregated from hospital listings across over 100 different state departments and federal sources.  See: [Data Documentation](https://www.arcgis.com/sharing/rest/content/items/6ac5e325468c4cb9b905f1728d6fbf0f/info/metadata/metadata.xml?format=default&output=html)

**Health Economics Indicators (2020):** In 2020, Professor Poirier aggregated several of the health economics indicators from a data publishing system called [Gapminder](https://www.gapminder.org/data/) in order to compile this dataset. Gapminder is an organization that aggregates statistics regarding global development from a number of reputable sources. The organization aims to dispel misconceptions about countries across the globe through these statistical sources. Most of the indicators that Prof. Poirier aggregated from Gapminder were originally sourced through the World Health Organization's [Global Health Observatory](https://www.who.int/data/gho). The World Health Organization compiles this data in order to monitor financial resource flows within health systems across the globe. 


```{r}
hospitals <- read.csv("https://raw.githubusercontent.com/aponce278/STS-115-2021/main/datasets/Hospitals.csv", stringsAsFactors = FALSE)

world_health_econ <- read.csv("https://raw.githubusercontent.com/lindsaypoirier/STS-115/master/datasets/world_health_econ.csv", stringsAsFactors = FALSE)

cases <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv", stringsAsFactors = FALSE)

#Do not worry about this line of code for now: 

cases <- 
  cases %>% 
  mutate(Total.Cases = 
           cases %>% 
           select(starts_with("X")) %>% 
           rowSums()
         ) %>%
  select(Province.State, Country.Region, Total.Cases)

hospitals$ZIP <- as.character(hospitals$ZIP)

hospitals$ZIP <- str_pad(hospitals$ZIP, 5, pad = "0") 

is.na(hospitals) <- hospitals == "NOT AVAILABLE"
is.na(hospitals) <- hospitals == -999
is.na(cases) <- cases == ""

hospitals$SOURCEDATE <- ymd_hms(hospitals$SOURCEDATE)
hospitals$VAL_DATE <- ymd_hms(hospitals$VAL_DATE)
```

### Import and clean your dataset. 

```{r}
#Copy the code chunks you used in lab #4 to clean your dataset

```

## Exploring Subsetted or Grouped Data

Last week, we explored how your data was defined, how it was categorized, and how missing values were represented. Through this exercise, we were able to develop a general overview of the obco-variation in the dataset, let's first go over how we can both zoom in and zoom out on our datasets. 

### Zooming in - Exploring Filtered Categorical Data

#### Filtering to a Category

Filtering is one way we can zoom in on our data - exploring only those observations that meet a particular criteria.

For instance, in the **Hospitals in the US** dataset, one criteria for being designated as a Critical Access Hospital is that the hospital must have 25 or fewer inpatient beds. We may want to see how the values for BEDS change when we filter to (or zoom into) just those observations representing critical access hospitals.  Below I will filter to rows that meet a criteria and then select a variable to examine from the filtered data. Notice how we can combine any number of dplyr (package) verbs using pipes (%>%).

```{r}
#Run this code chunk.

#df %>% filter(CATEGORICAL_VARIABLE == "VALUE") %>% select(CATEGORICAL_VARIABLE)
hospitals %>% filter(TYPE == "CRITICAL ACCESS") %>% select(BEDS) %>% summary()
```

From this table we can see that there are hospitals in the US that have been designated as critical access hospitals that have more than 25 beds. Since this does not align with the criteria for critical access hospitals, it is likely something that we will want to investigate further.

#### Filtering to Numeric Observations Above or Below a Threshold

We may also want to see which states have hospitals with more than 1200 beds. To do so, we would filter the data to those observations where BEDS is greater than 1200. The first time I do this below, I select() the NAME of the hospital and the STATE. This shows every hospital with more than 1200 beds, along with the STATE in which it is located. However, what if I only wanted to know which states had hospitals with more than 1200 beds? I wouldn't necessarily want to select() STATE in this case because this would show me the state for every observation in my filtered data. As you can see below, this means that CA would appear 7 times! Instead, I would want to check the distinct() STATES in the filtered data. Check out how I do this below. 

```{r}
#Run this code chunk.

#df %>% filter(NUMBERIC_VARIABLE > VALUE) %>% distinct(CATEGORICAL_VARIABLE)

#Lists name and state of hospitals with more than 1200 beds.
hospitals %>% filter(BEDS > 1200) %>% select(NAME, STATE) 

#Lists state for every hospital with more than 1200 beds in the dataset
hospitals %>% filter(BEDS > 1200) %>% select(STATE) 

#Lists the states wtih more than 1200 beds
hospitals %>% filter(BEDS > 1200) %>% distinct(STATE) 
```

### Zooming out - aka grouping common values and summarizing

Sometimes we want to see our data in aggregate. For instance, I may want to know the total number of hospital beds per state. To calculate this, I would need to group all of the hospital observations by state and then sum the total number of beds in each group. In such cases, we can call **group_by()** to aggregate the observations with common variable values into groups. Then we will call **summarize()** to perform a calculation within each of those groups. **summarize()** takes a set of values and a calculation method and returns a single value. For instance, if we call summarize() with a numeric column in our dataset and "mean" as a calculation method, it will return the average of all the numeric values in that column. When called in conjunction with group_by(), **summarize()** takes a set of values for each group and a calculation method and returns a single value for each group. 

For the same hospitals dataset, we will group the observations by STATE and then use summarize to calculate the sum of BEDS per state. Notice below how we are choosing to ignore NA values above by calling na.rm = TRUE. When we do so, we need to keep in mind that we are not summarizing across all observations in the dataset, but only those for which there is a value listed in the variable we are operating on. Because of this, I also calculate the number of observations in each group, the number of observations where the BEDS variable is missing, and the percentage of observations in the group where the variable is missing. This provides important context for how readily we can rely on these numbers. For instance, when you run the code below, note how in Alaska, the number of beds are missing for 28% of the observations. 

```{r}
#Run this code chunk.

#df %>% group_by(CATEGORICAL_VARIABLE) %>% summarize(NEW_VARIABLE_NAME = sum(NUMBERIC_VARIABLE, na.rm = TRUE)) %>% ungroup()

hospitals %>% 
  group_by(STATE) %>% #Group observations by state
  summarize(
    STATES_BEDS = sum(BEDS, na.rm = TRUE), #Calculate the sum of BEDS within each STATE group
    OBSERVATIONS = n(), #Calculate how many observations are in each STATE group
    MISSING_BEDS = sum(is.na(BEDS)), #Calculate how many NAs are in the BEDS variable in each STATE group
    PERCENT_MISSING = sum(is.na(BEDS))/n()*100) %>% #Divide the two values you just calculated to determine the percent of missing data
  ungroup()
```

> Notice that I close each of these calls with **ungroup()**. When we group_by() a variable, any subsequent function calls will continue to be performed on the grouped data, unless we ungroup() it. This can be important if we want to filter to specific values after we summarize() the data. Assuming that we don't want to perform a filter operation within each group but on the entire new dataframe created after summarizing, we need to ungroup() the data before performing the filter() operation. 

From this function, we see the number of beds across all hospitals per state. Depending on the question we are asking, this may or may not be relevant. For instance, if I'm wondering how much hospital infrastructure was prespared to support a rise in the number of Covid-19 patients in 202o, one (of a number of) factor(s) I need to consider before presenting this data is which types of hospitals were accepting Covid-19 patients. Were rehabilitation hospitals accepting patients? Psychiatric hospitals? Military hospitals?

At this moment, we may filter our data to only include beds at General Acute Care Hospitals. We also know that some hospitals in the dataset are closed. We need to also filter these out before presenting the data. Notice how below, I can do this by simply copying and pasting the code from above and adding one filter statement before grouping the data. 

```{r}
#Run this code chunk.

hospitals %>% 
  filter(TYPE == "GENERAL ACUTE CARE" & STATUS == "OPEN") %>%
  group_by(STATE) %>% #Group observations by state
  summarize(
    STATES_BEDS = sum(BEDS, na.rm = TRUE), #Calculate the sum of BEDS within each STATE group
    OBSERVATIONS = n(), #Calculate how many observations are in each STATE group
    MISSING_BEDS = sum(is.na(BEDS)), #Calculate how many NAs are in the BEDS variable in each STATE group
    PERCENT_MISSING = sum(is.na(BEDS))/n()*100) %>% #Divide the two values you just calculated to determine the percent of missing data
  ungroup()
```

In other words, often times to answer questions within a dataset, we need to both zoom in and out on data - honing in on certain observations and then generalizing across them. We cannot answer questions well if we don't have a good understanding of what's included in our data and how issues are defined. Had we not known that hospitals that are closed and hospitals that are classed as rehabs or psychiatric facilities were included in the data, we may have made some poor assumptions about the number of beds available. Also note how, in every step of data analysis, we have to make decisions about what to include and what to exclude in the analysis. Data analysts play a very active role in shaping the knowledge that gets produced from data. The numbers can never speak for themselves. 

### When I Need to Zoom In or Out

For some of you, these functions will be necessary to employ before performing operations across numeric variables in your dataset. This is because, as we learned last week, some of you have observational units that span multiple time periods, multiple geographies, or multiple issues. Before performing an operation across a numeric variable, we need to ensure all of the values in that variable are referring to observations reported across the same timeframe or geographic scale.

With the world_health_econ data, for example, every observation refers to a country *and a year*. Let's say that we wanted to call summary() on life_exp variable to compare life expectancies across countries. Without first zooming in to to a specific year, we would be including multiple values taken at the same place at different times. Let's filter the data to only include the most recent reporting year and then call summary():

```{r}
#Run this code chunk.

world_health_econ %>%
  filter(year == max(year, na.rm = TRUE)) %>% #Note that this is how we can fliter to the rows with the maximum value in a variable; in this case, this would be the most recent year. 
  select(life_exp) %>%
  summary()
```

In rarer cases, we will need to group_by() and summarize() our data before statistically analyzing it. This is the case with the cases dataset, which we have been studying for the past few weeks. Each observation in the cases dataset refers to a combination of things - a province and a country. The issue, as we noticed, is that not every country is reporting data at the province level. This means that sometimes the Total.Cases variable is referring to the number of cases in a country and sometimes it is referring to the number of cases in a Province. If we wanted to statistically analyze the number of cases across observations, we first need to transform the dataset so that each observation is reported at the same scale. In other words, we need to zoom out to standardize the observational unit across the dataset to the country level (since we do not always have data at the province level). To do that, we will need to group_by() Country.Region and then summarize the sum of Total.Cases.

```{r}
#Run this code chunk.

cases %>%
  group_by(Country.Region) %>%
  summarize(Total.Cases = sum(Total.Cases, na.rm = TRUE)) %>%
  ungroup()
```

Once we've done this, we can analyze the Total.Cases variable because we know that the number is always referring to the number of cases in a country.

Alternatively, we could also filter to one country to analyze numeric variables across provinces in that country. If I were to call summary() on the Total.Cases variable in the cases dataset, I would be gathering statistics across numbers reported at different geographic scales. Below, I filter the cases dataset to one Country - Canada - so that I'm gathering statistics across all provinces in Canada. 

```{r}
#Run this code chunk.

cases %>% 
  filter(Country.Region == "Canada") %>%
  select(Total.Cases) %>%
  summary()
```

Let's test the extent to which you will need to zoom in or zoom out to analyze numeric values your data. Select a **numeric variable** in your your dataset and complete the statement below. The following function selects the first value of the variable (in the dataset) you selected. To fill the blank, think what variables make up the unique key in your dataset. If you have more than one variable in your unique key, make sure that each is represented in your statement below. 


```{r}
#Use this structure:

#paste(df$NUMERIC_VARIABLE[1], "refers to a number/measure of [FILL NUMERIC VARIABLE] in a _____ in my dataset.")

#Example:
paste(hospitals$BEDS[1], "refers to a number of beds in a hospital in my dataset.")
paste(world_health_econ$pop[1], "refers to a number of people in a country in a given year in my dataset.")
paste(cases$Total.Cases[1], "refers to a number of cases in a country and/or province in my dataset.")

#Your answer here:


```

How did you fill in the last _____? 

Is your observational unit one thing (e.g. one hospital, or one country)? If this is the case, it will likely not be as essential for you to zoom in or zoom out before operating on numeric variables. **If so, we will say that you do not have qualified units of observation.**

OR 

Is your observational unit a combination of things or factors (e.g. one chemical reported at a particular facility or one census tract reporting in a particular year)? If this is the case, it will likely be essential for you to zoom in or zoom out before operating on numeric variables. **If so, we will say that you do have qualified units of observation.**

Think about what you might filter to in order to ensure that you will be comparing like observations (hint: it will involve a variable in your unique key). Perhaps you will filter to the most recent year, so that you can compare observations across geographies in that year. Or perhaps you will filter to a particular geography, so that you can compare observations across time in that geography. Or perhaps you will filter to a particular diagnosis group, so that you can compare costs across hospitals for that diagnosis. Or perhaps you will filter to a particular year and family type so that you can compare observations across counties in that year for that family type.

Characterize one way you might filter your data below. Be specific. Which variable in the dataset will you filter on and to what value(s) will you filter it to? 

```{r eval=FALSE}
Fill your response here. 
```

### Zooming in and/or Zooming Out on Your Own Data

Select one of the values that you identified from calling **distinct()** on a categorical variable in last week's lab (lab#4) Filter the dataset to the rows representing that value, select a numeric variable to explore, and then call **summary()**. If you have qualified units of observation, be sure to first zoom into a set of observations in your data (using filter()). 

```{r}
#Example: hospital beds (in the General Actue Care category) available in California in 2020.

hospitals %>% filter(STATUS == "OPEN" & STATE == "CA" & STATE == "CA" & TYPE == "GENERAL ACUTE CARE") %>% select(BEDS) %>% summary()

#Uncomment the appropriate lines below, and fill in your data frame, variables, and value. Run the code.

#_____ %>% filter(_____ == "_____") %>% select(_____) %>% summary()

#If you have qualified units of observation
#_____ %>% filter(_____ == _____ & _____ == "_____") %>% select(_____) %>% summary()

```

Think about your own research project. What question might this analysis help to address?

```{r eval=FALSE}
Fill your response here. 
```

Are there any other variables in your dataset that you need to take into consideration before directing this analysis towards answering that question? In other words, do you need to zoom into any specific areas of the dataset (by filtering) in order to appropriately address this question? 

```{r eval=FALSE}
Fill your response here. 
```

What insight can you draw from calling summary() on your filtered dataset?

```{r eval=FALSE}
Fill your response here. 
```

Now, select a numeric variable in your dataset that represents the extent or scale of the issue you are studying. Pick a number that you believe serves as a good indicator that this issue is at a notable extent or scale, and filter the dataset to all the rows greater than (or less than) this number. Check the remaining distinct values in a categorical variable in the dataset. If you have qualified units of observation, be sure to first zoom into a set of observations in your data (using filter()).

```{r}
#Uncomment the appropriate lines below, and fill in your data frame, variables, condition, and value. Run the code.
#_____ %>% filter(_____ _____ _____) %>% distinct(_____)

#If you have qualified units of observation
#_____ %>% filter(_____ == _____ & _____ _____ _____) %>% distinct(_____)

```

What question might this analysis help to address?

```{r eval=FALSE}
Fill your response here. 
```

Are there any other variables in your dataset that you need to take into consideration before directing this analysis towards answering that question? In other words, do you need to zoom into any specific areas of the dataset (by filtering) in order to appropriately address this question? 

```{r eval=FALSE}
Fill your response here. 
```

What insight can you draw from calling distinct on the filtered data?

```{r eval=FALSE}
Fill your response here. 
```

Select a categorical variable that you would like to group your data by, so that you can summarize some statistics across each grouping. For example: you may group your data by a particular year, by a particular location (such as a state or a region), or by a particular category. Then select a numeric variable in your dataset to summarize by. 

If you have qualified units of observation, you may want to group the data by one of the variables in your unique key. For instance, if your unique key is a county and year, then perhaps you want to group the data by county and summarize something across each year. If you have qualified units of observation and choose to group by a variable that is not in your unique key, then be sure to filter the data as you have been above. 

```{r}
#Uncomment the appropriate lines below, and fill in your data frame, variables, and summarize variable name, and math function. Then run the code.

#_____ %>% group_by(_____) %>% summarize(_____ = _____(_____, na.rm = TRUE), OBSERVATIONS = n(), MISSING = sum(is.na(_____)), PERCENT_MISSING = sum(is.na(_____))/n()*100)

#If you have qualified units of observation (and not grouping by the qualifier).
#_____ %>% filter(_____ == _____) %>% group_by(_____) %>% summarize(_____ = _____(_____, na.rm = TRUE), OBSERVATIONS = n(), MISSING = sum(is.na(_____)), PERCENT_MISSING = sum(is.na(_____))/n()*100)
```

What question might this analysis help to address?

```{r eval=FALSE}
Fill your response here. 
```

Combine any combination of the 4 verbs we have used so far (select, filter, group by, or summarize) to explore your dataset further. You may also use arrange, summary, or distinct. 

```{r}
#Fill your function here and then run the code.
```

What question might this analysis help to address?

```{r eval=FALSE}
Fill your response here. 
```

---

## Variation

Variation is the extent to which the values in a particular variable vary from observation to observation. Examining variation involves looking at the distribution of values in a particular column in the dataset. Do we have a whole bunch of one particular value in a certain variable, and very few of another? Or maybe, do we have a more even distribution of values across a variable?

### ggplot

At this point in the assignment, we will begin leveraging the Tidyverse package **ggplot** to create plots for visualizing the data. To create a plot with ggplot, we will follow this basic formula:

```{r eval=FALSE}
df %>% 
  ggplot(aes(x = VARIABLE_NAME)) + 
  CHART_TYPE
```

For example, for a bar chart (geom_bar), you will call:

```{r eval=FALSE}
df %>% 
  ggplot(aes(x = VARIABLE_NAME)) + 
  geom_bar()
```

For a column chart (geom_col), you will call:

```{r eval=FALSE}
df %>% 
  ggplot(aes(x = VARIABLE_NAME, y = VARIABLE_NAME)) + 
  geom_col()
```
  
Let's break that down a bit. First, you will call your dataframe (df). Following your dataframe and a pipe (%>%), you will call ggplot(), which basically tells R to prepare to create a plot. Inside ggplot, you will list *aesthetics*. These are variables in the dataset that you would like to appear on your plot. Setting x = VARIABLE_NAME tells ggplot() what variable to plot on the x-axis. Setting y = VARIABLE_NAME tells ggplot() what variable to plot on the y-axis. Finally, following a plus (+) sign, you tell ggplot which type of plot to create. The [ggplot cheatsheet](https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf) lists a number of plots that you can create with ggplot, as well as a number of different ways to style the plot. We will practice several of these below. 

For every plot that you produce, I will expect you to add a title and labels to the x and y axis. You can do this as follows:

```{r eval=FALSE}
df %>% 
  ggplot(aes(x = VARIABLE_NAME, y = VARIABLE_NAME)) + 
  geom_col() +
  labs(title = "FILL TITLE", x = "FILL X-AXIS LABEL", y = "FILL Y-AXIS LABEL")
```

There are also a number of useful tools for styling your plots. For instance we can set the theme of the plot to look a bit more polished by adding "+ theme_bw()" to the plot. I will do this for all plots in this lab.

```{r eval=FALSE}
df %>% 
  ggplot(aes(x = VARIABLE_NAME, y = VARIABLE_NAME)) + 
  geom_col() +
  labs(title = "FILL TITLE", x = "FILL X-AXIS LABEL", y = "FILL Y-AXIS LABEL") +
  theme_bw()
```

Two styling issues that may come up in most of your plots include:
* changing x or y axis tick numbers from scientific to comma notation: + scale_x_continuous(labels = scales::comma) OR + scale_y_continuous(labels = scales::comma)
* turning x axis tick marks 90 degrees so that they do not overlap: + theme(axis.text.x = element_text(angle = 90, hjust=1)) OR + theme(axis.text.y = element_text(angle = 90, hjust=1))

```{r eval=FALSE}
df %>% 
  ggplot(aes(x = VARIABLE_NAME, y = VARIABLE_NAME)) + 
  geom_col() +
  labs(title = "FILL TITLE", x = "FILL X-AXIS LABEL", y = "FILL Y-AXIS LABEL") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust=1)) + #Turn labels 90 degrees
  scale_x_continuous(labels = scales::comma) #Change labels from scientific to comma notation
```

So how do we visualize data variation with ggplot? Below I describe two different plots that you can leverage to visualize variation - a bar plot and a frequency plot. 

### Bar Plot

A *bar plot* displays the number of times each value appears in a categorical variable. This will tell us how the observations in the dataset *vary* in regards to that variable. In other words, this plot will communicate the number of observations in your dataset by that variable. 

```{r fig.height=5, fig.width=10}
#This is the structure

#df %>% ggplot(aes(x = CATEGORICAL_VARIABLE)) + geom_bar() + labs(title = "TITLE", x = "X-AXIS NAME", y = "Y-AXIS NAME")

#Run this code chunk.

hospitals %>% 
  ggplot(aes(x = TYPE)) + 
  geom_bar() +
  labs(title = "Number of Hospitals in the US by Type", x = "Type", y = "Count of Hospitals") + #Adds a title to the plot
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust=1)) #Changes x-axis tick labels 90 degrees 
```

Remember that this dataset includes hospitals that are designated as closed. Depending on the question we are trying to address, we may wish to zoom in to only the observations signifying a hospital that is open before creating this plot. 

```{r fig.height=5, fig.width=10}
#Run this code chunk.

#df %>% ggplot(aes(x = CATEGORICAL_VARIABLE)) + geom_bar() + labs(title = "TITLE", x = "X-AXIS NAME", y = "Y-AXIS NAME")

hospitals %>% 
  filter(STATUS == "OPEN") %>%
  ggplot(aes(x = TYPE)) + 
  geom_bar() +
  labs(title = "Number of Hospitals in the US that are Open by Type", x = "Type", y = "Count of Hospitals") + #Adds a title to the plot
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust=1)) #Changes x-axis tick labels 90 degrees 
```

##### What if I have qualified units of observation?

When we create a bar plot, we are counting the number of observations that fall into each category. If there is only one variable that makes up your unique key, that one variable will represent what is being counted. However, if there are multiple variables in your unique key, then identifying what it is that you are counting becomes a little more complicated. For instance, let's say your data reports the population of each country each year as it does in the world_health_econ dataset. Now let's say that you wanted to plot the number of countries per continent. If you were to call:

```{r}
#Run this code chunk.

world_health_econ %>% 
  ggplot(aes(x = continent)) + 
  geom_bar() +
  labs(title = "Number of Countries per Continent - Incorrect", x = "Continent", y = "Count of Countries") + #Adds a title to the plot
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust=1)) #Changes x-axis tick labels 90 degrees 
```

... you would be counting the combination of the number of countries and years per continent. There are not 800 countries in Africa, but Africa appears in the dataset 800 times because each country in Africa has several rows in the dataset - one for each reporting year. In other words, each country is represented in the bar for every year that it was included in the dataset. The y-axis does not just represent countries but both countries and years. If we want the y-axis to only be counting one thing, then we need to first reduce the dataset to values in a particular context. You can do this by filtering the data as you had been doing above.

```{r}
#Run this code chunk.

world_health_econ %>% 
  filter(year == max(year, na.rm = TRUE)) %>%
  ggplot(aes(x = continent)) + 
  geom_bar() +
  labs(title = "Number of Countries per Continent in the most Recent Reporting Year", x = "Continent", y = "Count of Countries") + #Adds a title to the plot
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust=1)) #Changes x-axis tick labels 90 degrees
```

> Note the addition to my title above. If you filter your dataset, the formula for titling changes a bit to Frequency of [x-axis variable name] across _____ in [filtered value]

#### Select a categorical variable for which you want to visualize the frequency of times it appears in the dataset. 

I recommend that you select one of the same categorical variables that you analyzed last week. If you have qualified units of observation, be sure to filter your data first so that all of the observations you are counting have one variables as a unique key.

```{r fig.height=5, fig.width=10}
#Uncomment the line below and fill appropriately. Add a title and labels to your plots, and adjust its style to be legible. Then run the code.

#_____ %>% ggplot(aes(x = _____)) + geom_bar()

#If qualified:
#_____ %>% filter(_____ == _____) %>% ggplot(aes(x = _____)) + geom_bar()
```

Reflect on the distribution of categories in the dataset. Is there an even distribution of observations across each category, or are certain categories more represented than others? Why might this be?

```{r eval=FALSE}
Fill response here. 
```

### Frequency Plot

A *frequency plot* will display the distribution of values in a numeric variable within a designated set of increments. This will tell us how the observations in the dataset *vary* in regards to that variable. In other words, this plot will communicate the number of observations in your dataset broken down into increments of the values in that variable. 

Consider the plot below. This plot tells us the distribution of beds across open hospitals. It tells us how many hospitals there are in each increment of 10 beds.

```{r fig.height=5, fig.width=10}
#Run this code chunk.

#df %>% ggplot(aes(x = NUMERIC_VARIABLE)) + geom_freqpoly(binwidth = 1) + labs(title = "TITLE", x = "X-AXIS NAME", y = "Y-AXIS NAME")

hospitals %>% 
  filter(STATUS == "OPEN") %>%
  ggplot(aes(x = BEDS)) +
  geom_freqpoly(binwidth = 10) +
  labs(title = "Distribution of Beds across Hospitals in the US that are Open", x = "Beds", y = "Count of Hospitals") +
  theme_bw()
```

Note that binwidth refers to the size of the increments at which frequency will be calculated. Above the binwidth is set to 10. This means that ggplot will display the frequency of each value at intervals of 10, 20, 30, 40, etc. When we set the bindwidth to 1, ggplot will display the frequency of each value at intervals of 1, 2, 3, 4. etc. What difference does this make? 

Notice what happens when we set the binwidth to 1. While above we count the number of hospitals with 0-10 beds  10-20 beds, 20-30 beds, etc, this will count the number of hospitals with 0-1 beds, 1-2 beds, 2-3 beds, and so on. Because we are counting the number in such small increments, the plot will look much more jagged and will take a longer time to load. This plot displays the counts in *finer* granularity than the first plot.

```{r fig.height=5, fig.width=10}
#Run this code chunk.

hospitals %>% 
  filter(STATUS == "OPEN") %>%
  ggplot(aes(x = BEDS)) +
  geom_freqpoly(binwidth = 1) +
  labs(title = "Distribution of Beds across Hospitals in the US that are Open", x = "Beds", y = "Count of Hospitals") +
  theme_bw()
```

When we set the binwidth to 100, we count the number of hospitals with 0-100 beds, 100-200 beds, 200-300 beds, and so on. Because we are counting the number in larger increments, the plot will look much smoother and will take less time to load. This plot displays the counts in *thicker* granularity than the first plot.

```{r fig.height=5, fig.width=10}
#Run this code chunk.

hospitals %>% 
  filter(STATUS == "OPEN") %>%
  ggplot(aes(x = BEDS)) +
  geom_freqpoly(binwidth = 100) +
  labs(title = "Distribution of Beds across Hospitals in the US that are Open", x = "Beds", y = "Count of Hospitals") +
  theme_bw()
```

#### Titling a Frequency Plot

Note how I titled my plot above: "Distribution of Beds across Hospitals in the US that are Open" Consider again what makes each observation unique. A good formula for titling frequency plots is as follows:

Frequency of [x-axis variable name] across _____ 

Again, we can fill in the blank with our observational unit. The [x-axis variable name] should be your x-label and "Count of ______" (filled the same as above) should be your y-label.

#### What if I have qualified units of observation?

Let's talk about what would happen if I were to make a frequency plot of the Total.Cases in the cases dataset:

```{r fig.height=5, fig.width=10}
#Run this code chunk.

cases %>% 
  ggplot(aes(x = Total.Cases)) + 
  geom_freqpoly(binwidth = 10000) +
  labs(title = "Distribution of Cases across ____", x = "Total Cases", y = "Count of _____") + # To add titles and labels
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust=1)) + #Turn labels 90 degrees
  scale_x_continuous(labels = scales::comma) #Change labels from scientific to comma notation
```

We know that each observation in the cases dataset refers to a province/country pair. So here I'm counting the number of province/countries in each bracket of total cases. Since only some countries in this dataset are broken into provinces, we are comparing counts of cases across different geographic scales - sometimes at the province level and sometimes at the country level. In this case, it makes more sense to total up the number of cases per country and then plot the distribution of cases across countries. We can use group_by() and summarize() to do this:

```{r fig.height=5, fig.width=10}
#Run this code chunk.

cases %>% 
  group_by(Country.Region) %>%
  summarize(Total.Cases = sum(Total.Cases, na.rm = TRUE)) %>%
  ungroup() %>%
  ggplot(aes(x = Total.Cases)) + 
  geom_freqpoly(binwidth = 100000) +
  labs(title = "Distribution of Cases across Countries", x = "Total Cases", y = "Count of Countries") + # To add titles and labels
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust=1)) + #Turn labels 90 degrees
  scale_x_continuous(labels = scales::comma) #Change labels from scientific to comma notation
```

What about the world_health_econ data? Without separating out these units of observation, we would be visualizing multiple values reported at the same place at different periods in time (i.e. every year since 1995). Instead, we want to zoom into a single year in the dataset so we are just comparing values across place. 

```{r fig.height=5, fig.width=10}
#Run this code chunk.

world_health_econ %>% 
  filter(year == max(year, na.rm = TRUE)) %>%
  ggplot(aes(x = tot_health_sp_pp)) + 
  geom_freqpoly(binwidth = 100) +
  labs(title = "Distribution of Total Health Spending per Person across Countries in 2010", x = "Total Health Spending per Person", y = "Count of Countries") + # To add titles and labels
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust=1)) + #Turn labels 90 degrees
  scale_x_continuous(labels = scales::comma) #Change labels from scientific to comma notation
```

> Note the addition to my title above. If you filter your dataset, the formula for titling changes a bit to Frequency of [x-axis variable name] across _____ in [filtered value]

#### Select a numeric variable for which you want to visualize the distribution of a set of values. 

Be sure to select a variable that describes something about the observational unit and not another categorical variable in your dataset. If you have qualified units of observation, be sure to first zoom into a set of observations in your data (using filter()).

```{r fig.height=5, fig.width=10}
#Uncomment the line below and fill appropriately. Add a title and labels to your plots. Run the code.
#_____ %>% ggplot(aes(x = _____)) + geom_freqpoly(binwidth = _____) 
```

This gives us information about the distribution of values in the dataset. Reflect on the distribution of values. Are the values evenly distributed, or are certain values more represented than others? Why might this be? 

```{r eval=FALSE}
Fill response here. 
```

## Co-variation

Co-variation is the extent to which the values that constitute two or more variables vary in relation to one another. To visualize co-variation, we might create:

### Count Plots

*Count plots* display how many times two categorical values appear together in a dataset. For instance, in the count plot below, we display the number of open hospitals with each combination of OWNER and TYPE.

```{r fig.height=5, fig.width=10}
#Run this code chunk.

#df %>% ggplot(aes(x = CATEGORICAL_VARIABLE, y = CATEGORICAL_VARIABLE)) + geom_count()

hospitals %>% 
  filter(STATUS == "OPEN") %>%
  ggplot(aes(x = TYPE, y = OWNER)) + 
  geom_count() +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  labs(title = "Number of Hospitals in the US that are Open by Type and Ownership", x = "Type", y = "Ownership")
```

#### Titling a Count Plot

Note how I titled my plot above: "Number of Hospitals in the US that are Open by Type and Ownership" Consider again what makes each observation unique. Here I am counting the observations by Type and Ownership, and in order to know what I'm counting, I need to know what each observation refers to. A good formula for titling count plots is as follows:

Number of _____ by [x-axis variable name] and [y-axis variable name]

The blank should be filled with your unit of observation. The [x-axis variable name] should be your x-label and [y-axis variable name] should be your y-label.

#### What if I have qualified units of observation?

If this is the case I would encourage you to include one of the qualified variables in the x or y-axis. For instance, if the unique key for world_health_econ is country and year, I can include year as the y-axis below to visualize how counts of observations change over time. (Notice how they don't in the plot below.) Alternatively, if you wish to compare two categorical variables that are not a part of the unique key, be sure to filter the data so that only one variable constitutes the unique key.

```{r fig.height=5, fig.width=10}
#Run this code chunk.

world_health_econ %>% 
  ggplot(aes(x = continent, y = as.factor(year))) + 
  geom_count() +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  labs(title = "Number of Countries by Continent and Year", x = "Continent", y = "Year")
```

### Stacked Frequency Plots 

*Stacked frequency plots* display the distribution of numeric values in a variable, grouped by a categorical value. For instance, the plot below display the distribution of beds across open hospitals, categorized by the hospital type.

```{r fig.height=5, fig.width=10}
#Run this code chunk.

#df %>% ggplot(aes(x = NUMERIC_VARIABLE, col = CATEGORICAL_VARIABLE)) + geom_freqpoly(binwidth = 1)

hospitals %>% 
  filter(STATUS == "OPEN") %>%
  ggplot(aes(x = BEDS, col = TYPE)) + 
  geom_freqpoly(binwidth = 100) +
  labs(title = "Frequency of Beds across Hospitals in the US that are Open by Hospital Type", x = "Beds", y = "Count of Hospital", col = "Type") + # To add titles and labels
  theme_bw() 
```

Stacked frequency plots work best when categorizing by a variable with 10 or fewer distinct values. Otherwise, it can be tricky to see the differences in color gradations. If all of your categorical variables have more than 10 distinct values, one thing you might consider is first filtering your data to a few representative categories. For instance, let's say that I would like to see the distribution of beds in hospitals across states. Since there are 57 states, if I were to categorize the distribution by state, the plot would be very difficult to read.

```{r fig.height=5, fig.width=10}
#Run this code chunk.

#df %>% ggplot(aes(x = NUMERIC_VARIABLE, col = CATEGORICAL_VARIABLE)) + geom_freqpoly(binwidth = 1)

hospitals %>% 
  filter(STATUS == "OPEN") %>%
  ggplot(aes(x = BEDS, col = STATE)) + 
  geom_freqpoly(binwidth = 100) +
  labs(title = "Frequency of Beds across Hospitals in the US that are Open by Hospital State", x = "Beds", y = "Count of Hospital", col = "Type") + # To add titles and labels
  theme_bw() 
```

In this case, we may wish to first filter our data to a few representative states using **%in%**.

```{r fig.height=5, fig.width=10}
#Run this code chunk.

#df %>% ggplot(aes(x = NUMERIC_VARIABLE, col = CATEGORICAL_VARIABLE)) + geom_freqpoly(binwidth = 1)

hospitals %>% 
  filter(STATUS == "OPEN" & STATE %in% (c("CA", "MA", "NY", "FL", "LA"))) %>%
  ggplot(aes(x = BEDS, col = STATE)) + 
  geom_freqpoly(binwidth = 100) +
  labs(title = "Frequency of Beds across Hospitals in the US that are Open by Hospital State", x = "Beds", y = "Count of Hospital", col = "Type") + # To add titles and labels
  theme_bw() 
```

#### Titling a Stacked Frequency Plot

Note how I titled my plot above: "Frequency of Beds across Hospitals in the US that are Open by Hospital Type" Consider again what makes each observation unique. Here I am counting the observations by number of Beds and Hospital Type. A good formula for titling stacked frequency plots is as follows: 

Frequency of [x-axis variable name] across _____ by [col variable name]

The blank should be filled with your unit of observation. The [x-axis variable name] should be your x-label, "Count of ______" (filled the same as above) should be your y-label, and the [col variable name] should be your col-label.

#### What if I have qualified units of observation?

If this is the case I would encourage you to include one of the qualified variables in the col variable. For instance, if world_health_econ is qualified by country and year, I can include year as the col variable below to visualize how the frequency of countries with various life expectancies changes over time. 

```{r fig.height=5, fig.width=10}
#Run this code chunk.

#df %>% ggplot(aes(x = NUMERIC_VARIABLE, col = CATEGORICAL_VARIABLE)) + geom_freqpoly(binwidth = 1)

world_health_econ %>% 
  ggplot(aes(x = life_exp, col = as.factor(year))) + 
  geom_freqpoly(binwidth = 5) +
  theme_bw() +
  labs(title = "Frequency of Life Expectancies across Countries by Year", x = "Life Expectancy", y = "Count of Countries", col = "Life Expectancy") 
```

> Note that this is one plot that is particularly susceptible to missing data. If certain countries did not report data in certain years, the count of countries in a bracket will appear lower, not necessarily because fewer countries fell within a certain life expectancy bracket, but because fewer countries reported that life expectancy. 

Alternatively, you could zoom in to one value in one of your qualified variables, filtering to a specific subset of observations and then divide by a different categorical variable. 

```{r fig.height=5, fig.width=10}
#Run this code chunk.

#df %>% ggplot(aes(x = NUMERIC_VARIABLE, col = CATEGORICAL_VARIABLE)) + geom_freqpoly(binwidth = 1)

world_health_econ %>% 
  filter(year == max(year, na.rm = TRUE)) %>%
  ggplot(aes(x = life_exp, col = continent)) + 
  geom_freqpoly(binwidth = 5) +
  theme_bw() +
  labs(title = "Frequency of Life Expectancies across Countries by Continent in 2010", x = "Life Expectancy", y = "Count of Countries", col = "Continent")
```

### Point plots

*Point plots* display the relationship between a categorical variable and a numeric variable. For instance, the plot below displays a relationship between hospital type and the number of beds at the hospital. Notably, unlike the plots we have been viewing until now, with point plots, we see a point for every observation in the dataset. Because point plots display every observation (rather than aggregating them into other polygons and lines), they are particularly good for seeing outliers in the data. However, with large datasets, this also can mean that points will overlap. Note that the first plot below exhibits overplotting - when the data represented on a plot overlaps, making it difficult to discern one point from the next. There are various tools available to deal with over-plotting. You can reduce the size of points on the plot, increase their transparency, or set them to slightly offset each other (known as adding jitter). We do all three in the second plot below.

```{r fig.height=5, fig.width=10}
#Run this code chunk.

#df %>% ggplot(aes(x = CATEGORICAL_VARIABLE, y = NUMERIC_VARIABLE)) + geom_point()

hospitals %>% 
  filter(STATUS == "OPEN") %>%
  ggplot(aes(x = TYPE, y = BEDS)) + 
  geom_point() +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  labs(title = "Number of Beds in Hospitals by Type", x = "Type", y = "Number of Beds")


hospitals %>% 
  filter(STATUS == "OPEN") %>%
  ggplot(aes(x = TYPE, y = BEDS)) + 
  geom_jitter(size = 0.5, alpha = 0.1) + #Change geom_point to geom_jitter, reduce the size, add transparency for overplotting
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  labs(title = "Number of Beds in Hospitals by Type", x = "Type", y = "Number of Beds")

```

#### Titling a Point Plot

Note how I titled my plot above: "Number of Beds in Hospitals in the US that are Open by Type" Here I am displaying the number of beds by Type. A good formula for titling point plots is as follows:

Number/Measure of [y-axis variable name] in _____ by [x-axis variable name] 

The blank should be filled with your unit of observation. The [x-axis variable name] should be your x-label and "Number/Measure of [y-axis variable name]" should be your y-label.

#### What if I have qualified units of observation?

If this is the case I would encourage you to filter your data as you have been doing elsewhere. For instance if world_health_econ is qualified by country and year, I can filter to the most recent year before creating a point plot of the private share of health spending by continent.

```{r fig.height=5, fig.width=10}
#Run this code chunk.

world_health_econ %>% 
  filter(year == max(year, na.rm = TRUE)) %>%
  ggplot(aes(x = continent, y = priv_share_health_sp)) + 
  geom_point(size = 2, alpha = 0.8) +  
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust=1)) +
  labs(title = "Private Share of Health Spending in Countries by Continent in 2010", x = "Continent", y = "Private Share of Health Spending") 
```

### Scatterplots

*Scatterplots* display the relationship or correlation between two numeric variables. For instance, below we plot the relationship between the BEDS variable and the POPULATION variable in the hospitals dataset. 

There are different ways to characterize the correlations between variables in data. We may consider the *strength* of a correlation, the *shape* of a correlation, and whether the correlation is positive or negative. 
* Two variables in a scatterplot can be said to have a strong correlation when points are clustered closely to a central line or curve. The more scattered throughout the plot the points are, the weaker the correlation.
* Two variables in a scatterplot can be said to have a linear correlation when the scatterplot tends to produce a straight line. This means that the rate of change between two variables is steady. However, when a scatterplot produces a curve, this indicates that the rate of change between two variables is not as constant.
* Two variables in a scatterplot can be said to have a positive correlation when the points move upward from the bottom left corner towards the top right corner of the plot. This means that as values in variable increases, the values in the other variable also increase. When points move downward from the top left corner to the bottom right corner of the plot, we can say that the variables negatively correlation. This means that as values in variable increases, the values in the other variable decreases.

```{r fig.height=8, fig.width=10}
#Run this code chunk.

#ggplot(df, aes(x = NUMERIC_VARIABLE, y = NUMERIC_VARIABLE)) + geom_point()

hospitals %>% 
  filter(STATUS == "OPEN") %>%
  ggplot(aes(x = BEDS, y = POPULATION)) + 
  geom_point(size = 0.5) +
  theme_bw() +
  labs(title = "Relationship between Hospital Beds and Population in the US", x = "Beds", y = "Population") 
```

> Note that this plot has a strong, linear positive correlation. As BEDS increase in this variable, POPULATION also tends to increase. 

#### Titling a Scatterplot

Note how I titled my plot above: "Relationship between Hospital Beds and Population in the US" A good formula for titling scatterplots is as follows:

Relationship between _____ [x-axis variable name] and [y-axis variable name] 

The blank should be filled with your unit of observation. The [x-axis variable name] should be your x-label and [y-axis variable name]" should be your y-label.

#### What if I have qualified units of observation?

If this is the case I would encourage you to filter your plot to one value in one of your qualified variables. For instance if world_health_econ is qualified by country and year, I can filter to the most recent year before creating a point plot of the private share of health spending by continent.

```{r fig.height=8, fig.width=10}
#Run this code chunk.

#ggplot(df, aes(x = NUMERIC_VARIABLE, y = NUMERIC_VARIABLE)) + geom_point()

world_health_econ %>% 
  filter(year == max(year, na.rm = TRUE)) %>%
  ggplot(aes(x = tot_health_sp_pp, y = life_exp, size = pop, col = continent)) + 
  geom_point(shape = 21, stroke = 1) +
  labs(title = "Relationship between Country Total Health Spending Per Person and Life Expectancy", x = "Total Health Spending Per Person", y = "Life Expectancy", size = "Population", col = "Continent") + 
  theme_bw() +
  scale_size_continuous(range = c(1, 10), labels = scales::comma)
```

> Note that this plot has a weaker, curvilinear, positive correlation. As Total Health Spending per Person increases in this variable, Life Expectancy also tends to increase, but the rate of change at which it increases is not constant.  

Have you heard the quip "Correlation does not equal causation"? This is particularly important to consider here. IN a later lab we will examine some confounding variables that may be mediating how values appear to correlate in our data. For now, it's important to note that just because we see a correlation between total health spending and life expectancy does not mean that increasing total health spending in a country **causes** life expectancy to increase. This is of course a complex issue with lots of other variables involved. 

### Produce two plots that represent co-variation in your dataset. 

You need not include every plot I described above. Be sure to zoom in or out on your data if you have qualified units of observation. 

```{r fig.height=8, fig.width=10}
#Fill the code for plot 1 here. Add a title and labels to your plots. Be sure to adjust for overplotting.
```

What question might this analysis help to address?

```{r eval=FALSE}
Fill your response here. 
```

What insight can you draw from this plot?

```{r eval=FALSE}
Fill your response here. 
```

```{r fig.height=8, fig.width=10}
#Fill the code for plot 2 here. Add a title and labels to your plots. Be sure to adjust for overplotting.
```

What question might this analysis help to address?

```{r eval=FALSE}
Fill your response here. 
```

What insight can you draw from this plot?

```{r eval=FALSE}
Fill your response here. 
```
